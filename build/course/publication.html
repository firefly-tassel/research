<!DOCTYPE HTML>
<!--
  Twenty by HTML5 UP
  html5up.net | @ajlkn
  Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
  <head>
    <title>Publication</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">
    <link rel="shortcut icon" href="favicon.ico"/>
	<link rel="bookmark" href="favicon.ico"/>
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
  </head>
  <body class="no-sidebar is-preload">
    <div id="page-wrapper">

      <!-- Header -->
        <header id="header">
          <h1 id="logo" style="font-size: medium; font-weight: 500"><a href="index.html">Hung-yi Lee (李宏毅)</a></h1>
          <nav id="nav">
            <ul>
              <li class="menu"><a href="index.html">Home</a></li>
              <li class="menu"><a href="honor.html">Honor</a></li>
              <li class="menu"><a href="research.html">Research</a></li>
              <li class="menu"><a href="talk.html">Talk</a></li>
              <li class="current"><a href="publication.html">Publication</a></li>
              <li class="submenu">
                <a href="#">Course</a>
                <ul>
                  <li class="submenu">
                    <a href="#">Machine Learning</a>
                    <ul>
                      <li><a href="ml/2021-spring.html">2021 Spring</a></li>
                      <li><a href="ml/2020-spring.html">2020 Spring</a></li>
                      <li><a href="/ml/2019-spring.html">2019 Spring</a></li>
                      <li><a href="ml/2017-fall.html">2017 Fall</a></li>
                      <li><a href="ml/2027-spring.html">2017 Spring</a></li>
                      <li><a href="ml/2016-fall.html">2016 Fall</a></li>
                    </ul>
                  </li>
                  <li class="submenu">
                    <a href=#>DLHLP</a>
                    <ul>
                      <li><a href="dlhlp/2020-spring.html">2020 Spring</a></li>
                    </ul>
                  </li>
                  <li class="submenu">
                    <a href="#">MLDS</a>
                    <ul>
                      <li><a href="mlds/2018-spring.html">2018 Spring</a></li>
                      <li><a href="mlds/2017-spring.html">2017 Spring</a></li>
                      <li><a href="mlds/2015-fall.html">2015 Fall</a></li>
                    </ul>
                  </li>
                  <li class="submenu">
                    <a href="#">Linear Algebra</a>
                    <ul>
                      <li><a href="la/2021-fall.html">2021 Fall</a></li>
                      <li><a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/LA_2020/policy.pdf" target="_blank" rel="noreferrer noopener">2020 Fall</a></li>
                      <li><a href="la/2019-fall.html">2019 Fall</a></li>
                      <li><a href="la/2018-fall.html">2018 Fall</a></li>
                      <li><a href="la/2016-spring.html">2016 Spring</a></li>
                    </ul>
                  </li>
                  <li><a href="circuit/2014-fall.html">Circuit</a></li>
                </ul>
              </li>
              <li class="menu"><a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists" target="_blank" rel="noopener noreferrer">Youtube</a></li>
            </ul>
          </nav>

        </header>

      <!-- Main -->
        <article id="main">

          <header class="special container">
            <span class="icon solid fa-scroll"></span>
            <h2>Publication</strong></h2>
          </header>

          <!-- One -->
            <section class="wrapper style1 container" style="font-size: 20px">
              <nav>
                <div class="nav nav-tabs" id="nav-tab" role="tablist">
                  <a class="nav-link active" id="nav-home-tab" data-bs-toggle="tab" href="#nav-home" role="tab" aria-controls="nav-home" aria-selected="true">Conference Paper</a>
                  <a class="nav-link" id="nav-profile-tab" data-bs-toggle="tab" href="#nav-profile" role="tab" aria-controls="nav-profile" aria-selected="false">Journal Paper</a>
                  <a class="nav-link" id="nav-contact-tab" data-bs-toggle="tab" href="#nav-contact" role="tab" aria-controls="nav-contact" aria-selected="false">Preprint</a>
                </div>
              </nav>
              <div class="tab-content" id="nav-tabContent">
                <div class="tab-pane fade show active" id="nav-home" role="tabpanel" aria-labelledby="nav-home-tab">
                  <input class="form-control" id="myInput" type="text" placeholder="Search.." style="margin: 10px">
                  <ol id="myDIV">
				    <!-- This is the template for conference paper
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>論文標題</b></p>
						  <p class="card-text">作者</br>會議,年份</p>
                        </div>
                      </div>
                    </li>
                    -->
					
										<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b> SUPERB: Speech processing Universal PERformance Benchmark  </b></p>
						  <p class="card-text">Shu-wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I Lai, Kushal Lakhotia, Yist Y. Lin, Andy T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko-tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, Hung-yi Lee</br>INTERSPEECH, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2105.01051" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>				
					
					
					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations </b></p>
						  <p class="card-text">Jheng-hao Lin, Yist Y. Lin, Chung-Ming Chien, Hung-yi Lee </br>INTERSPEECH, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2104.02901" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>	
					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Utilizing Self-supervised Representations for MOS Prediction</b></p>
						  <p class="card-text">Wei-Cheng Tseng, Chien-yu Huang, Wei-Tsung Kao, Yist Y. Lin, Hung-yi Lee</br>INTERSPEECH, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2104.03017" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>	
					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Voting for the right answer: Adversarial defense for speaker verification </b></p>
						  <p class="card-text">Haibin Wu, Yang Zhang, Zhiyong Wu, Dong Wang and Hung-yi Lee </br>INTERSPEECH, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>	
					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Stabilizing Label Assignment for Speech Separation by Self-supervised Pre-training</b></p>
						  <p class="card-text">Sung-Feng Huang, Shun-Po Chuang, Da-Rong Liu, Yi-Chen Chen, Gene-Ping Yang, Hung-yi Lee  </br>INTERSPEECH, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2010.15366" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>	
					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Towards Lifelong Learning of End-to-end ASR </b></p>
						  <p class="card-text">Heng-Jui Chang, Hung-yi Lee, Lin-shan Lee </br>INTERSPEECH, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2104.01616" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>	
					
					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Auto-KWS 2021 Challenge: Task, Datasets, and Baselines </b></p>
						  <p class="card-text">Jingsong Wang, Yuxuan He, Chunyu Zhao, Qijie Shao, Wei-Wei Tu, Tom Ko, Hung-yi Lee, lei xie </br>INTERSPEECH, 2021 </p>
                        </div>
                      </div>
                    </li>						

					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Investigating the Reordering Capability in CTC-based Non-Autoregressive End-to-End Speech Translation</b></p>
						  <p class="card-text">Shun-Po Chuang, Yung-Sung Chuang, Chih-Chiang Chang, Hung-yi Lee </br> ACL Findings, 2021 </p>
                        </div>
                      </div>
                    </li>						

					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Put Chatbot into Its Interlocutor's Shoes: New Framework to Learn Chatbot Responding with Intention</b></p>
						  <p class="card-text">Hsuan Su, Jiun-Hao Jhan, Fan-yun Sun, Saurav Sahay, Hung-yi Lee</br>NAACL, 2021 <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2103.16429" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p>
                        </div>
                      </div>
                    </li>

                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Investigating on Incorporating Pretrained and Learnable Speaker Representations for Multi-Speaker Multi-Style Text-to-Speech</b></p>
						  <p class="card-text">Chung-Ming Chien, Jheng-Hao Lin, Chien-yu Huang, Po-chun Hsu, Hung-yi Lee</br>ICASSP, 2021  <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2103.04088" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a>
</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>One Shot Learning for Speech Separation</b></p>
						  <p class="card-text">Yuan-Kuei Wu, Kuan-Po Huang, Yu Tsao, Hung-yi Lee</br>ICASSP, 2021  <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2011.10233" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a>
</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>FragmentVC: Any-to-Any Voice Conversion by End-to-End Extracting and Fusing Fine-Grained Voice Fragments With Attention</b></p>
						  <p class="card-text">Yist Y. Lin, Chung-Ming Chien, Jheng-Hao Lin, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2021  <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2010.14150" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a>
</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>AGAIN-VC: A One-shot Voice Conversion using Activation Guidance and Adaptive Instance Normalization</b></p>
						  <p class="card-text">Yen-Hao Chen, Da-Yi Wu, Tsung-Han Wu, Hung-yi Lee</br>ICASSP, 2021  <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2011.00316" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p> 
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Adversarial defense for automatic speaker verification by cascaded self-supervised learning models</b></p>
						  <p class="card-text">Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-yi Lee</br>ICASSP, 2021  <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2102.07047" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p> 
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Semi-Supervised Spoken Language Understanding via Self-Supervised Speech and Language Model Pretraining</b></p>
						  <p class="card-text">Cheng-I Lai, Yung-Sung Chuang, Hung-Yi Lee, Shang-Wen Li, James Glass</br>ICASSP, 2021  <a class="btn btn-primary btn-sm" style="background-color: #000000; border-style: none" href="https://arxiv.org/abs/2010.13826" target="_blank" rel="noopener" role="button"><i class="fas fa-file-pdf"></i></a></p> 
                        </div>
                      </div>
                    </li>

					<li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Hierarchical Prosody Modeling For Non-Autoregressive Speech Synthesis</b></p>
						  <p class="card-text">Chung-Ming Chien, Hung-yi Lee</br>SLT, 2021</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Audio Albert: A Lite Bert For Self-Supervised Learning Of Audio Representation</b></p>
                          <p class="card-text">Po-Han Chi, Pei-Hung Chung, Tsung-Han Wu, Chun-Cheng Hsieh, Yen-Hao Chen, Shang-Wen Li, Hung-yi Lee</br>SLT, 2021</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>How Far Are We From Robust Voice Conversion: A Survey</b></p>
                          <p class="card-text">Tzu-hsien Huang, Jheng-hao Lin, Hung-yi Lee</br>SLT, 2021</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Defending Your Voice: Adversarial Attack On Voice Conversion</b></p>
                          <p class="card-text">Chien-yu Huang, Yist Y. Lin, Hung-yi Lee, Lin-shan Lee</br>SLT, 2021</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>End-To-End Whispered Speech Recognition With Frequency-Weighted Approaches And Pseudo Whisper Pre-Training</b></p>
                          <p class="card-text">Heng-Jui Chang, Alexander H. Liu, Hung-yi Lee, Lin-shan Lee</br>SLT, 2021</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Pretrained Language Model Embryology: The Birth of ALBERT</b></p>
                          <p class="card-text">David C. Chiang, Sung-Feng Huang, Hung-yi Lee</br>EMNLP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>TaylorGAN: Neighbor-Augmented Policy Update for Sample-Efficient Natural Language Generation</b></p>
                          <p class="card-text">Chun-Hsing Lin, Siang-Ruei Wu, Hung-Yi Lee, Yun-Nung Chen</br>NeurIPS, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Understanding Self-Attention of Self-Supervised Audio Transformers</b></p>
                          <p class="card-text">Shu-wen Yang, Andy T. Liu, Hung-yi Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning</b></p>
                          <p class="card-text">Haibin Wu, Andy T. Liu, Hung-yi Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>WG-WaveNet: Real-Time High-Fidelity Speech Synthesis without GPU</b></p>
                          <p class="card-text">Po-chun Hsu, Hung-yi Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition and Adaptation</b></p>
                          <p class="card-text">Yi-Chen Chen, Jui-Yang Hsu, Cheng-Kuang Lee, Hung-yi Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture</b></p>
                          <p class="card-text">Da-Yi Wu, Yen-Hao Chen, Hung-Yi Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis Using Discrete Speech Representation</b></p>
                          <p class="card-text">Tao Tu, Yuan-Jui Chen, Alexander H. Liu, Hung-yi Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>SpeechBERT: An Audio-and-text Jointly Learned Language Model for End-to-end Spoken Question Answering</b></p>
                          <p class="card-text">Yung-Sung Chuang, Chi-Liang Liu, Hung-Yi Lee, Lin-shan Lee</br>INTERSPEECH, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Worse WER, but Better BLEU? Leveraging Word Embedding as Intermediate in Multitask End-to-End Speech Translation</b></p>
                          <p class="card-text">Shun-Po Chuang, Tzu-Wei Sung, Alexander H Liu, Hung-yi Lee</br>ACL, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>MOCKINGJAY: UNSUPERVISED SPEECH REPRESENTATION LEARNING WITH DEEP BIDIRECTIONAL TRANSFORMER ENCODERS</b></p>
                          <p class="card-text">Andy T. Liu, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, Hung-yi Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>WHAT DOES A NETWORK LAYER HEAR? ANALYZING HIDDEN REPRESENTATIONS OF END-TO-END ASR THROUGH SPEECH SYNTHESIS</b></p>
                          <p class="card-text">Chung-Yi Li, Pei-Chieh Yuan, Hung-Yi Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>INTERRUPTED AND CASCADED PERMUTATION INVARIANT TRAINING FOR SPEECH SEPARATION</b></p>
                          <p class="card-text">Gene-Ping Yang, Szu-Lin Wu, Yao-Wen Mao, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>SEQUENCE-TO-SEQUENCE AUTOMATIC SPEECH RECOGNITION WITH WORD EMBEDDING REGULARIZATION AND FUSED DECODING</b></p>
                          <p class="card-text">Alexander H. Liu, Tzu-Wei Sung, Shun-Po Chuang, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>TRAINING A CODE-SWITCHING LANGUAGE MODEL WITH MONOLINGUAL DATA</b></p>
                          <p class="card-text">Shun-Po Chuang, Tzu-Wei Sung, Hung-Yi Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>TOWARDS UNSUPERVISED SPEECH RECOGNITION AND SYNTHESIS WITH QUANTIZED SPEECH REPRESENTATION LEARNING</b></p>
                          <p class="card-text">Alexander H. Liu, Tao Tu, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>ONE-SHOT VOICE CONVERSION BY VECTOR QUANTIZATION</b></p>
                          <p class="card-text">Da-Yi Wu, Hung-yi Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Defense against adversarial attacks on spoofing countermeasures of ASV</b></p>
                          <p class="card-text">Haibin Wu, Songxiang Liu, Helen Meng, Hung-yi Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>META LEARNING FOR END-TO-END LOW-RESOURCE SPEECH RECOGNITION</b></p>
                          <p class="card-text">Jui-Yang Hsu, Yuan-Jui Chen, Hung-yi Lee</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>SELF-SUPERVISED DEEP LEARNING FOR FISHEYE IMAGE RECTIFICATION</b></p>
                          <p class="card-text">Chun-Hao Chao, Pin-Lun Hsu, Hung-Yi Lee, Yu-Chiang Frank Wang</br>ICASSP, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>LAMOL: LAnguage MOdeling for Lifelong Language Learning</b></p>
                          <p class="card-text">Fan-Keng Sun, Cheng-Hao Ho, Hung-Yi Lee</br>ICLR, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Order-free Learning Alleviating Exposure Bias in Multi-label Classification</b></p>
                          <p class="card-text">Che-Ping Tsai, Hung-Yi Lee</br>AAAI, 2020</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Adversarial attacks on spoofing countermeasures of automatic speaker verification</b></p>
                          <p class="card-text">Songxiang Liu, Haibin Wu, Hung-yi Lee, Helen Meng</br>ASRU, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Zero-shot Reading Comprehension by Cross-lingual Transfer Learning with Multi-lingual Language Representation Model</b></p>
                          <p class="card-text">Tsung-Yuan Hsu, Chi-Liang Liu and Hung-yi Lee</br>EMNLP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Polly Want a Cracker: Analyzing Performance of Parroting on Paraphrase Generation Datasets</b></p>
                          <p class="card-text">Hong-Ren Mao and Hung-Yi Lee</br>EMNLP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Tree Transformer: Integrating Tree Structures into Self-Attention</b></p>
                          <p class="card-text">Yaushian Wang, Hung-Yi Lee and Yun-Nung Chen</br>EMNLP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs</b></p>
                          <p class="card-text">Yi-Lin Tuan, Yun-Nung Chen and Hung-yi Lee</br>EMNLP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization</b></p>
                          <p class="card-text">Ju-chieh Chou, Cheng-chieh Yeh, Hung-yi Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion</b></p>
                          <p class="card-text">Andy T. Liu, Po-chun Hsu and Hung-yi Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Personalized Dialogue Response Generation Learned from Monologues</b></p>
                          <p class="card-text">Feng-Guang Su, Aliyah Hsu, Yi-Lin Tuan and Hung-yi Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>End-to-end Text-to-speech for Low-resource Languages by Cross-Lingual Transfer Learning</b></p>
                          <p class="card-text">Yuan-Jui Chen, Tao Tu, Cheng-chieh Yeh, Hung-yi Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Code-switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation</b></p>
                          <p class="card-text">Ching-Ting Chang, Shun-Po Chuang, Hung-Yi Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Completely Unsupervised Phoneme Recognition By A Generative Adversarial Network Harmonized With Iteratively Refined Hidden Markov Models</b></p>
                          <p class="card-text">Kuan-yu Chen, Che-ping Tsai, Da-Rong Liu, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Noise Adaptive Speech Enhancement using Domain Adversarial Training</b></p>
                          <p class="card-text">Chien-Feng Liao, Yu Tsao, Hung-yi Lee and Hsin-Min Wang</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Speech Separation with Time-and-Frequency Cross-domain Joint Embedding and Clustering</b></p>
                          <p class="card-text">Gene-Ping Yang, ChaoI Tuan, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Generative Adversarial Networks for Unpaired Voice Transformation on Impaired Speech</b></p>
                          <p class="card-text">Li-Wei Chen, Hung-Yi Lee, Yu Tsao</br>INTERSPEECH, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>, ICASSP, 2019</b></p>
                          <p class="card-text">Che-Ping Tsai, Hung-Yi Lee, Adversarial Learning of Label Dependency: A Novel Framework for Multi-class Classification</br>ICASSP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Towards Audio to Scene Image Synthesis using Generative Adversarial Network</b></p>
                          <p class="card-text">Chia-Hung Wan, Shun-Po Chuang, Hung-Yi Lee</br>ICASSP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Mitigating the Impact of Speech Recognition Errors on Spoken Question Answering by Adversarial Domain Adaptation</b></p>
                          <p class="card-text">Chia-Hsuan Lee, Yun-Nung Chen, Hung-Yi Lee</br>ICASSP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Towards End-to-end Speech-to-text Translation with Two-pass Decoding</b></p>
                          <p class="card-text">Tzu-Wei Sung, Jun-You Liu, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Adversarial Training of End-to-end Speech Recognition Using a Criticizing Language Model</b></p>
                          <p class="card-text">Alexander H. Liu, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Using Deep-Q Network to Select Candidates from N-best Speech Recognition Hypotheses for Enhancing Dialogue State Tracking</b></p>
                          <p class="card-text">Richard Tzong-Han Tsai, Chia-Hao Chen, Chun-Kai Wu, Yu-Cheng Hsiao, Hung-Yi Lee</br>ICASSP, 2019</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks</b></p>
                          <p class="card-text">Yau-Shian Wang, Hung-Yi Lee</br>EMNLP, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improving Unsupervised Style Transfer in End-to-End Speech Synthesis with End-to-End Speech Recognition</b></p>
                          <p class="card-text">Da-Rong Liu, Chi-Yu Yang, Szu-Lin Wu, Hung-Yi Lee</br>SLT, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>ODSQA: Open-domain Spoken Question Answering Dataset</b></p>
                          <p class="card-text">Chia-Hsuan Lee, Shang-Ming Wang, Huan-Cheng Chang, Hung-Yi Lee</br>SLT, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Rhythm-Flexible Voice Conversion without Parallel Data Using Cycle-GAN over Phoneme Posteriorgram Sequences</b></p>
                          <p class="card-text">Cheng-chieh Yeh, Po-chun Hsu, Ju-chieh Chou, Hung-yi Lee, Lin-shan Lee</br>SLT, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval</b></p>
                          <p class="card-text">Yi-Chen Chen, Sung-Feng Huang, Chia-Hao Shen, Hung-yi Lee, Lin-shan Lee</br>SLT, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition Errors on Listening Comprehension</b></p>
                          <p class="card-text">Chia-Hsuan Li, Szu-Lin Wu, Chi-Liang Liu, Hung-yi Lee</br>INTERSPEECH, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator</b></p>
                          <p class="card-text">Pei-Hung Chung, Kuan Tung, Ching-Lun Tai, Hung-Yi Lee</br>INTERSPEECH, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations</b></p>
                          <p class="card-text">Ju-chieh Chou, Cheng-chieh Yeh, Hung-yi Lee, Lin-shan Lee</br>INTERSPEECH, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings</b></p>
                          <p class="card-text">Da-Rong Liu, Kuan-Yu Chen, Hung-Yi Lee, Lin-shan Lee</br>INTERSPEECH, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Language Transfer of Audio Word2Vec: Learning Audio Segment Representations without Target Language Data</b></p>
                          <p class="card-text">Chia-Hao Shen, Janet Y. Sung, Hung-Yi Lee</br>ICASSP, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Query-by-example Spoken Term Detection using Attention-based Multi-hop Networks</b></p>
                          <p class="card-text">Chia-Wei Ao, Hung-yi Lee</br>ICASSP, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Domain Independent Key Term Extraction from Spoken Content based on Context and Term Location Information</b></p>
                          <p class="card-text">Hsien-Chin Lin, Chi-Yu Yang, Hung-Yi Lee, Lin-Shan Lee</br>ICASSP, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Scalable Sentiment for Sequence-to-sequence Chatbot Response with Performance Analysis</b></p>
                          <p class="card-text">Chih-Wei Lee, Yau-Shian Wang, Tsung-Yuan Hsu, Kuan-Yu Chen, Hung-Yi Lee, Lin-Shan Lee</br>ICASSP, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Segmental Audio Word2vec: Representing Utterances as Sequences of Vectors with Applications in Spoken Term Detection</b></p>
                          <p class="card-text">Yu-Hsuan Wang, Hung-Yi Lee, Lin-Shan Lee</br>ICASSP, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Supervised and Unsupervised Transfer Learning for Question Answering</b></p>
                          <p class="card-text">Yu-An Chung, Hung-Yi Lee, James Glass</br>NAACL, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Query-based Attention CNN for Text Similarity Map</b></p>
                          <p class="card-text">Tzu-Chien Liu, Yu-Hsueh Wu, Hung-Yi Lee</br>ICCV, 2018</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Mitigating the Impact of Speech Recognition Errors on Chatbot using Sequence-to-sequence Model</b></p>
                          <p class="card-text">Pin-Jung Chen, I-Hung Hsu, Yi Yao Huang, Hung-Yi Lee</br>ASRU, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Seeing and Hearing Too: Audio Representation for Video Captioning</b></p>
                          <p class="card-text">Shun Po Chuang, Chia-Hung Wan, Pang-Chi Huang, Chi-Yu Yang, Hung-Yi Lee</br>ASRU, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Personalized Word Representations Carrying Personalized Semantics Learned from Social Network Posts</b></p>
                          <p class="card-text">Zih-Wei Lin, Tzu-Wei Sung, Hung-Yi Lee, Lin-Shan Lee</br>ASRU, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Learning Chinese Word Representations From Glyphs Of Characters</b></p>
                          <p class="card-text">Tzu-Ray Su, Hung-Yi Lee</br>EMNLP, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Gate Activation Signal Analysis for Gated Recurrent Neural Networks and Its Correlation with Phoneme Boundaries</b></p>
                          <p class="card-text">Yu-Hsuan Wang, Cheng-Tao Chung, Hung-yi Lee</br>INTERSPEECH, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Order-Preserving Abstractive Summarization for Spoken Content based on Connectionist Temporal Classification</b></p>
                          <p class="card-text">Bo-Ru Lu, Frank Shyu, Yun-Nung Chen, Hung-Yi Lee, Lin-Shan Lee</br>INTERSPEECH, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Recurrent Neural Network based Language Modeling with Controllable External Memory</b></p>
                          <p class="card-text">Wei-Jen Ko, Bo-Hsiang Tseng, Hung-yi Lee</br>ICASSP, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Personalized Acoustic Modeling by Weakly Supervised Multi-task Deep Learning using Acoustic Tokens Discovered from Unlabeled Data</b></p>
                          <p class="card-text">Cheng-Kuan Wei, Cheng-Tao Chung, Hung-yi Lee, Lin-Shan Lee</br>ICASSP, 2017</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Abstractive Headline Generation for Spoken Content by Attentive Recurrent Neural Networks with ASR Error Modeling”</b></p>
                          <p class="card-text">Lang-Chi Yu, Hung-yi Lee, Lin-Shan Lee</br>SLT, 2016</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Hierarchical Attention Model for Improved Machine Comprehension of Spoken Content</b></p>
                          <p class="card-text">Wei Fang, Juei-Yang Hsu, Hung-yi Lee, Lin-Shan Lee</br>SLT, 2016</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine</b></p>
                          <p class="card-text">Bo-Hsiang Tseng, Sheng-syun Shen, Hung-Yi Lee, Lin-Shan Lee</br>INTERSPEECH, 2016</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Interactive Spoken Content Retrieval by Deep Reinforcement Learning</b></p>
                          <p class="card-text">Yen-Chen Wu, Tzu-Hsiang Lin, Yang-De Chen, Hung-Yi Lee, Lin-Shan Lee</br>INTERSPEECH, 2016</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Audio Word2Vec: Unsupervised Learning of Audio Segment Representations Using Sequence-to-Sequence Autoencoder</b></p>
                          <p class="card-text">Yu-An Chung, Chao-Chung Wu, Chia-Hao Shen, Hung-Yi Lee, Lin-Shan Lee</br>INTERSPEECH, 2016</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Neural Attention Models for Sequence Classification: Analysis and Application to Key Term Extraction and Dialogue Act Detection</b></p>
                          <p class="card-text">Sheng-syun Shen, Hung-Yi Lee</br>INTERSPEECH, 2016</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Towards Structured Deep Neural Network for Automatic Speech Recognition</b></p>
                          <p class="card-text">Yi-Hsiu Liao, Hung-yi Lee, Lin-shan Lee</br>ASRU, 2015</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Personalizing Universal Recurrent Neural Network Language Model with User Characteristic Features by Social Network Crowdsourcing</b></p>
                          <p class="card-text">Bo-Hsiang Tseng, Hung-yi Lee, Lin-Shan Lee</br>ASRU, 2015</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>An Iterative Deep Learning Framework for Unsupervised Discovery of Speech Features and Linguistic Units with Applications on Spoken Term Detection</b></p>
                          <p class="card-text">Cheng-Tao Chung, Cheng-Yu Tsai, Hsiang-Hung Lu, Chia-Hsiang Liu, Hung-yi Lee, Lin-shan Lee</br>ASRU, 2015</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Structuring Lectures in Massive Open Online Courses (MOOCs) for Efficient Learning by Linking Similar Sections and Predicting Prerequisites</b></p>
                          <p class="card-text">Sheng-syun Shen, Hung-yi Lee, Shang-wen Li, Victor Zue and Lin-shan Lee</br>INTERSPEECH, 2015</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Semantic Retrieval of Personal Photos using a Deep Autoencoder Fusing Visual Features with Speech Annotations Represented as Word/Paragraph Vectors</b></p>
                          <p class="card-text">Hung-tsung Lu, Yuan-ming Liou, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2015</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Personalized Speech Recognizer with Keyword-based Personalized Lexicon and Language Model using Word Vector Representations</b></p>
                          <p class="card-text">Ching-Feng Yeh, Yuan-ming Liou, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2015</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Graph-based Re-ranking using Acoustic Feature Similarity between Search Results for Spoken Term Detection on Low-resource Languages</b></p>
                          <p class="card-text">Hung-yi Lee, Yu Zhang, Ekapol Chuangsuwanich, James Glass</br>INTERSPEECH, 2014</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Alignment of Spoken Utterances with Slide Content for Easier Learning with Recorded Lectures using Structured Support Vector Machine (SVM)</b></p>
                          <p class="card-text">Han Lu, Sheng-syun Shen, Sz-Rung Shiang, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2014</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Spoken Question Answering Using Tree-structured Conditional Random Fields and Two-layer Random Walk</b></p>
                          <p class="card-text">Sz-Rung Shiang, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2014</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Semantic Retrieval of Personal Photos using Matrix Factorization and Two-layer Random Walk Fusing Sparse Speech Annotations with Visual Features</b></p>
                          <p class="card-text">Yuan-ming Liou, Yi-sheng Fu, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2014</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Ensemble of Machine Learning and Acoustic Segment Model Techniques for Speech Emotion and Autism Spectrum Disorders Recognition</b></p>
                          <p class="card-text">Hung-yi Lee, Ting-yao Hu, How Jing, Yun-Fan Chang, Yu Tsao, Yu-Cheng Kao, Tsang-Long Pao</br>INTERSPEECH, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Unsupervised Domain Adaptation for Spoken Document Summarization with Structured Support Vector Machine</b></p>
                          <p class="card-text">Hung-yi Lee, Yu-yu Chou, Yow-Bang Wang, Lin-shan Lee</br>ICASSP, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Enhancing Query Expansion for Semantic Retrieval of Spoken Content with Automatically Discovered Acoustic Patterns</b></p>
                          <p class="card-text">Hung-yi Lee, Yun-Chiao Li, Cheng-Tao Chung, Lin-shan Lee</br>ICASSP, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Towards Unsupervised Semantic Retrieval of Spoken Content with Query Expansion based on Automatically Discovered Acoustic Patterns</b></p>
                          <p class="card-text">Yun-Chiao Li, Hung-yi Lee, Cheng-Tao Chung, Chun-an Chan, and Lin-shan Lee</br>ASRU, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Supervised Spoken Document Summarization Based on Structured Support Vector Machine with Utterance Clusters as Hidden Variables</b></p>
                          <p class="card-text">Sz-Rung Shiang, Hung-yi Lee, Lin-shan Lee</br>INTERSPEECH, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Recurrent Neural Network Based Language Model Personalization by Social Network Crowdsourcing</b></p>
                          <p class="card-text">Tsung-Hsien Wen, Aaron Heidel, Hung-yi Lee, Yu Tsao, Lin-shan Lee</br>INTERSPEECH, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Speaking Rate Normalization with Lattice-based Context-dependent Phoneme Duration Modeling for Personalized Speech Recognizers on Mobile Devices</b></p>
                          <p class="card-text">Ching-Feng Yeh, Hung-yi Lee and Lin-shan Lee</br>INTERSPEECH, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b> Interactive Spoken Content Retrieval by Extended Query Model and Continuous State Space Markov Decision Process</b></p>
                          <p class="card-text">Tsung-Hsien Wen, Hung-yi Lee, Pei-Hao Su, Lin-shan Lee</br>ICASSP, 2013</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Semantic Retrieval of Spoken Content by Language models Enhanced with Acoustic Similari"</b></p>
                          <p class="card-text">Hung-yi Lee, Tsung-Hsien Wen, Lin-shan Lee</br>SLT, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Personalized Language Modeling by Crowd Sourcing with Social Network Data for Voice Access of Cloud Applications</b></p>
                          <p class="card-text">Tsung-Hsien Wen, Hung-yi Lee, Lin-shan Lee</br>SLT, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Supervised Spoken Document Summarization Jointly Considering Utterance Importance and Redundancy by Structured Support Vector Machine</b></p>
                          <p class="card-text">Hung-yi Lee, Yu-yu Chou, Yow-Bang Wang, Lin-shan Lee</br>INTERSPEECH, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Open-Vocabulary Retrieval of Spoken Content with Shorter/Longer Queries Considering Word/Subword-based Acoustic Feature Similarity</b></p>
                          <p class="card-text">Hung-yi Lee, Po-wei Chou, Lin-shan Lee</br>INTERSPEECH, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Utterance-level Latent Topic Transition Modeling for Spoken Documents and its Application in Automatic Summarization</b></p>
                          <p class="card-text">Hung-yi Lee, Yun-nung Chen, Lin-shan Lee</br>ICASSP, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Interactive Spoken Content Retrieval with Different Types of Actions Optimized by a Markov Decision Process</b></p>
                          <p class="card-text">Tsung-Hsien Wen, Hung-yi Lee, Lin-shan Lee</br>INTERSPEECH, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Semantic Query Expansion and Context-based Discriminative Term Modeling for Spoken Document Retrieval</b></p>
                          <p class="card-text">Tsung-wei Tu, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Unsupervised Two-Stage Keyword Extraction from Spoken Documents by Topic Coherence and Support Vector Machine</b></p>
                          <p class="card-text">Yun-Nung Chen, Yu Huang, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Recognition of Highly Imbalanced Code-mixed Bilingual Speech with Frame-level Language Detection based on Blurred Posteriorgram</b></p>
                          <p class="card-text">Ching-Feng Yeh, Aaron Heidel, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2012</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Speech Summarization and Spoken Term Detection with Graphical Analysis of Utterance Similarities</b></p>
                          <p class="card-text">Hung-yi Lee, Yun-nung Chen, Lin-shan Lee</br>APSIPA ASC, 2011</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Spoken Term Detection Using Support Vector Machines based on Lattice Context Consistency</b></p>
                          <p class="card-text">Hung-yi Lee, Tsung-wei Tu, Chia-ping Chen, Chao-yu Huang, Lin-shan Lee </br>ICASSP, 2011</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Spoken Term Detection using Support Vector Machines with Acoustic and Context Features from Pseudo-relevance Feedback</b></p>
                          <p class="card-text">Tsung-wei Tu, Hung-yi Lee, Lin-shan Lee</br>ASRU, 2011</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Spoken Term Detection with Graph-based Re-ranking in Feature Space</b></p>
                          <p class="card-text">Yun-nung Chen, Chia-ping Chen, Hung-yi Lee, Chun-an Chan, Lin-shan Lee</br>ICASSP, 2011</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>A Framework Integrating Different Relevance Feedback Scenarios and Approaches for Spoken Term Detection</b></p>
                          <p class="card-text">Hung-yi Lee, Chia-ping Chen, Ching-feng Yeh, Lin-shan Lee</br>SLT, 2010</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Spoken Term Detection by Discriminative Training of Acoustic Models based on User Relevance Feedback</b></p>
                          <p class="card-text">Hung-yi Lee, Chia-ping Chen, Ching-feng Yeh, Lin-shan Lee</br>INTERSPEECH, 2010</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Integrating Recognition and Retrieval with User Feedback: A New Framework for Spoken Term Detection</b></p>
                          <p class="card-text">Hung-yi Lee and Lin-shan Lee</br>ICASSP, 2010</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Spoken Term Detection by Feature Space Pseudo-Relevance Feedback</b></p>
                          <p class="card-text">Chia-ping Chen, Hung-yi Lee, Ching-feng Yeh, Lin-shan Lee</br>INTERSPEECH, 2010</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>An Initial Attempt to Improve Spoken Term Detection by Learning Optimal Weights for Different Indexing Features</b></p>
                          <p class="card-text">Yu-Hui Chen, Chia-Chen Chou, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2010</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Spoken Term Detection from Bilingual Spontaneous Speech Using Code-switched Lattice-based Structures for Words and Subword Units</b></p>
                          <p class="card-text">Hung-yi Lee, Yueh-Lien Tang, Hao Tang, Lin-shan Lee</br>ASRU, 2009</p>
                        </div>
                      </div>
                    </li>
                    <li>
                      <div class="card w-75">
                        <div class="card-body">
                          <p class="card-title"><b>Improved Lattice-based Spoken Document Retrieval by Directly Learning from the evaluation Measures</b></p>
                          <p class="card-text">Chao-hong Meng, Hung-yi Lee, Lin-shan Lee</br>ICASSP, 2009</p>
                        </div>
                      </div>
                    </li>

                  </ol>
                </div>
                <div class="tab-pane fade" id="nav-profile" role="tabpanel" aria-labelledby="nav-profile-tab">
				    <!--期刊模板 -->
                    <!--
                    <div style="margin: 10px; text-align: justify">
                      作者, 
					  <a href="文章連結" target="_blank" rel="noopener noreferrer">文章標題</a>, 
					  期刊的資訊
					</div>

					-->
					                    <div style="margin: 10px; text-align: justify">
                      Shun-Po Chuang, Alexander H. Liu, Tzu-Wei Sung, Hung-yi Lee,
					  <a href="https://ieeexplore.ieee.org/document/9257188" target="_blank" rel="noopener noreferrer" >Improving Automatic Speech Recognition and Speech Translation via Word Embedding Prediction</a>, 
					  IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 93-105, Nov. 2021
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Yi-Chen Chen, Sung-Feng Huang, Hung-yi Lee, Yu-Hsuan Wang, Chia-Hao Shen, 
					  <a href="https://ieeexplore.ieee.org/document/8736337" target="_blank" rel="noopener noreferrer" >Audio Word2vec: Sequence-to-sequence Autoencoding for Unsupervised Learning of Audio Segmentation and Representation</a>, 
					  IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 27, no. 9, pp. 1481-1493, Sept. 2019
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Chia-Hsuan Lee, Hung-yi Lee, Szu-Lin Wu, Chi-Liang Liu, Wei Fang, Juei-Yang Hsu, Bo-Hsiang Tseng, <a href="https://ieeexplore.ieee.org/document/8700217" target="_blank" rel="noopener noreferrer" >"Machine Comprehension of Spoken Content: TOEFL Listening Test and Spoken SQuAD"</a>, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 27, no. 9, pp. 1469-1480, Sept. 2019
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Yi-Lin Tuan, Hung-Yi Lee, <a href="https://ieeexplore.ieee.org/document/8403313" target="_blank" rel="noopener noreferrer" >"Improving Conditional Sequence Generative Adversarial Networks by Stepwise Evaluation"</a>, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 27, no. 4, pp. 788-798, April 2019 
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-Yi Lee, Pei-Hung Chung, Yen-Chen Wu, Tzu-Hsiang Lin, Tsung-Hsien Wen, <a href="https://ieeexplore.ieee.org/document/8403313" target="_blank" rel="noopener noreferrer" >"Interactive Spoken Content Retrieval by Deep Reinforcement Learning"</a>, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 26, no. 12, pp. 2447-2459, Dec. 2018
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-yi Lee, Bo-Hsiang Tseng, Tsung-Hsien Wen, Yu Tsao, <a href="http://ieeexplore.ieee.org/document/7765093/" target="_blank" rel="noopener noreferrer" >"Personalizing Recurrent Neural Network Based Language Model by Social Network"</a>, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 25, no. 3, pp. 519-530, March 2017 
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Shun-Yao Shih, Fan-Keng Sun, Hung-yi Lee, <a href="https://arxiv.org/abs/1809.04206" target="_blank" rel="noopener noreferrer" >"Temporal Pattern Attention for Multivariate Time Series Forecasting"</a>, accepted by the journal track of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD) 
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Lin-shan Lee, James Glass, Hung-yi Lee, Chun-an Chan, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/Overview.pdf" target="_blank" rel="noopener noreferrer" >"Spoken Content Retrieval —Beyond Cascading Speech Recognition with Text Retrieval"</a>, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol.23, no.9, pp.1389-1420, Sept. 2015 
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-yi Lee, Ching-feng Yeh, Yun-Nung Chen, Yu Huang, Sheng-Yi Kong and Lin-shan Lee, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/LectureFinal.pdf" target="_blank" rel="noopener noreferrer" >“Spoken Knowledge Organization by Semantic Structuring and a Prototype Course Lecture System for Personalized Learning”</a>, IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol.22, no.5, pp.883-898, May 2014 (Figure 9 of the article selected as journal cover)
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-yi Lee, Po-wei Chou, Lin-shan Lee, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/PRF-Graph-Final.pdf" target="_blank" rel="noopener noreferrer" >"Improved open-vocabulary spoken content retrieval with word and subword lattices using acoustic feature similarity"</a>, Computer Speech & Language, Volume 28, Issue 5, pp. 1045-1065, Sept. 2014
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-yi Lee, Lin-shan Lee, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/EstFianl.pdf" target="_blank" rel="noopener noreferrer" >"Improved Semantic Retrieval of Spoken Content by Document/Query Expansion with Random Walk over Acoustic Similarity Graphs"</a>IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol.22, no.1, pp.80-94, Jan. 2014 (Figure 2 of the article selected as journal cover)
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-yi Lee, Lin-shan Lee, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/PRF-SVM-Final.pdf" target="_blank" rel="noopener noreferrer" >"Enhanced Spoken Term Detection Using Support Vector Machines and Weighted Pseudo Examples"</a>,IEEE Transactions on Audio, Speech, and Language Processing, vol.21, no.6, pp.1272-1284, June 2013
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Hung-yi Lee, Chia-ping Chen, Lin-shan Lee, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/RetrievalFinal.pdf" target="_blank" rel="noopener noreferrer" >"Integrating Recognition and Retrieval with Relevance Feedback for Spoken Term Detection"</a>, IEEE Transactions on Audio, Speech, and Language Processing, vol.20, no.7, pp.2095-2110, Sept. 2012
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Yi-cheng Pan, Hung-yi Lee, Lin-shan Lee, <a href="http://speech.ee.ntu.edu.tw/~tlkagk/paper/ThomasFinal.pdf" target="_blank" rel="noopener noreferrer" >"Interactive Spoken Document Retrieval With Suggested Key Terms Ranked by a Markov Decision Process"</a>, IEEE Transactions on Audio, Speech, and Language Processing, vol.20, issue.2, pp. 632-645, Feb. 2012
                    </div>
                </div>
                <div class="tab-pane fade" id="nav-contact" role="tabpanel" aria-labelledby="nav-contact-tab">
				 
				 <!-- arxiv 模板 -->
                    <!--
				    <div style="margin: 10px; text-align: justify">
                      作者, 
					  <a href="連結" target="_blank" rel="noopener noreferrer" >
					  "標題"</a>,
					  arXiv preprint, 年份
                    </div>
                    -->
                    <div style="margin: 10px; text-align: justify">
                      Tsung-Han Wu, Chun-Cheng Hsieh, Yen-Hao Chen, Po-Han Chi, Hung-yi Lee, 
					  <a href="https://arxiv.org/pdf/2006.05174v2.pdf" target="_blank" rel="noopener noreferrer" >
					  "Hand-crafted Attention is All You Need? A Study of Attention on Self-supervised Audio Transformer"</a>,
					  arXiv preprint, 2020
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Yuan-Kuei Wu, Chao-I Tuan, Hung-yi Lee, Yu Tsao, <a href="https://arxiv.org/pdf/2005.09966.pdf" target="_blank" rel="noopener noreferrer" >"SADDEL: Joint Speech Separation and Denoising Model based on Multitask Learning"</a>, arXiv preprint, 2020
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Chao-I Tuan, Yuan-Kuei Wu, Hung-yi Lee, Yu Tsao, <a href="https://arxiv.org/pdf/1912.03884.pdf" target="_blank" rel="noopener noreferrer" >"MITAS: A Compressed Time-Domain Audio Separation Network with Parameter Sharing"</a>, arXiv preprint, 2019
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Po-chun Hsu, Chun-hsuan Wang, Andy T. Liu, Hung-yi Lee, <a href="https://arxiv.org/pdf/1912.02461.pdf" target="_blank" rel="noopener noreferrer" >"Towards Robust Neural Vocoding for Speech Generation: A Survey"</a>, arXiv preprint, 2019
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Chia-Hsuan Lee, Hung-Yi Lee, <a href="https://arxiv.org/pdf/1907.06042.pdf" target="_blank" rel="noopener noreferrer" >Cross-Lingual Transfer Learning for Question Answering</a>, arXiv preprint, 2019
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Yi-Chen Chen, Chia-Hao Shen, Sung-Feng Huang, Hung-yi Lee, <a href="https://arxiv.org/pdf/1803.10952.pdf" target="_blank" rel="noopener noreferrer" >"Towards Unsupervised Automatic Speech Recognition Trained by Unaligned Speech and Text only"</a>, arXiv preprint, 2018
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Yi-Lin Tuan, Jinzhi Zhang, Yujia Li, Hung-yi Lee, <a href="https://arxiv.org/pdf/1808.07982.pdf" target="_blank" rel="noopener noreferrer" >"Proximal Policy Optimization and its Dynamic Version for Sequence Generation"</a>, arXiv preprint, 2018
                    </div>
                    <div style="margin: 10px; text-align: justify">
                      Da-Rong Liu, Shun-Po Chuang, Hung-yi Lee, <a href="https://arxiv.org/pdf/1611.08656.pdf" target="_blank" rel="noopener noreferrer" >"Attention-based Memory Selection Recurrent Network for Language Modeling"</a>, arXiv preprint, 2016
                    </div>
                  
                </div>
              </div>
            </section>

        </article>

      <!-- Footer -->
        <footer id="footer">

          <ul class="icons">
            <li><a href="https://www.facebook.com/profile.php?id=100000149111577" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
            <li><a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists" class="icon brands fa-youtube"><span class="label">Youtube</span></a></li>
          </ul>

          <ul class="copyright">
            <li>&copy; Untitled</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
          </ul>

        </footer>

    </div>

    <!-- Scripts -->
      <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/js/bootstrap.bundle.min.js" integrity="sha384-ygbV9kiqUc6oa4msXn9868pTtWMgiQaeYH7/t7LECLbyPA2x65Kgf80OJFdroafW" crossorigin="anonymous"></script>
      <script src="assets/js/jquery.min.js"></script>
      <script src="assets/js/jquery.dropotron.min.js"></script>
      <script src="assets/js/jquery.scrolly.min.js"></script>
      <script src="assets/js/jquery.scrollgress.min.js"></script>
      <script src="assets/js/jquery.scrollex.min.js"></script>
      <script src="assets/js/browser.min.js"></script>
      <script src="assets/js/breakpoints.min.js"></script>
      <script src="assets/js/util.js"></script>
      <script src="assets/js/main.js"></script>
      <script>
        $(document).ready(function(){
          $("#myInput").on("keyup", function() {
            var value = $(this).val().toLowerCase();
              $("#myDIV li").filter(function() {
                $(this).toggle($(this).text().toLowerCase().indexOf(value) > -1)
              });
            });
          });
      </script>
  </body>
</html>
